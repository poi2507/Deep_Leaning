{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 함성곱 신경망(CNN)\n",
    "\n",
    "합성곱 신경망(Convolution Neural Network, CNN)\n",
    "CNN 은 이미지 인식과 음성인식 등 다양한 곳에 사용되는데, 특히 이미지 인식 분야에서 많이 사용된다.\n",
    "\n",
    "### 전체 구조\n",
    "\n",
    "CNN 도 지금까지 본 신경망 블록처럼 계층을 조합해서 만들 수 있다. 합성곱 계층과 풀링 계층이 새롭게 등장한다.\n",
    "\n",
    "지금까지 본 신경망은 인접하는 계층의 모든 뉴런과 결합되어 있었다.\n",
    "이를 완전연결(Fully-Connected)라 하며, 완전히 연결된 계층 Affine 계층이라는 이름으로 구현했다.\n",
    "\n",
    "\n",
    "|완전연결 게층|CNN 으로 이뤄진 네트워크|\n",
    "|---|---|\n",
    "|![](/Users/taewoong/Documents/NLP_1/img/IMG_A5E6C83E54F7-1.jpeg)|![](/Users/taewoong/Documents/NLP_1/img/IMG_D9AB7E803B42-1.jpeg)|\n",
    "\n",
    "\n",
    "CNN 에서는 새로은 '합성곱 계층'과 '풀링 계층'이 추가된다. CNN의 계층은 'Conv-ReLU-(Pooling)'흐름으로 연결된다.\n",
    "CNN에서 주목할 또 다른 점은 출력에 가까운 층에서는 Affine-ReLU 구성을 사용할 수 있다는 것이다. 또 마지막 계층에서는 Affine-SofrMax 조합을 그대로 사용한다.\n",
    "\n",
    "### 합성곱 계층\n",
    "\n",
    "CNN 에서는 패딩, 스트라이드 등 CNN 고유의 용어가 등장한다. 또 계층 사이에 3차원 데이터 같이 입체적인 데이터가 흐른다는 점에서 완전 연결 신경망과 다르다.\n",
    "\n",
    "### 완전연결 계층의 문제점\n",
    "\n",
    "완전연결 계층에서는 인점하는 계층의 뉴런이 모두 연결되고 출력의 수는 임의로 정할수 있다.\n",
    "완전 연결 계층의 문제점은 **데이터의 형상이 무시**된다는 사실이다.\n",
    "완전연결 계층에 입력할 때는 3차원 데이터를 평평한 1차원 데이터로 평탄화해줘야 한다.\n",
    "이미지는 3차원 데이터 형상이며 이 형상에는 소중한 공간적 정보가 담겨 있다.\n",
    "완전연결 계층은 형상을 무시하고 모든 입력 데이터를 동등한 뉴런으로 취급하여 현상에 담긴 정보를 살릴 수 없다.\n",
    "\n",
    "함성곱계층은 현상을 유지한다. 이미지도 3차원 데이터로 입력 받으면, 마찬가지로 다음 계층에도 3차원 데이터로 전달한다. 그래서 CNN 에서는 이미지 처럼 형상을 가진 데이터를 제대로 이해할(가능성이 있는) 것이다.\n",
    "\n",
    "CNN 에서는 합성곱 계층의 입출력데이터를 특징맵이라고도 한다.\n",
    "\n",
    "### 합성곱 연산\n",
    "\n",
    "합성곱 계층에서의 합성곱 연산을 처리한다. 합성곱 연산은 이미지 처리에서 말하는 필터 연산에 해당한다.\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_5568C63BCD53-1.jpeg)\n",
    "\n",
    "합성곱 연산은 입력데이터에 필터를 적용한다. 이 예에서 입력데이터는 세로•가로 뱡향의 형상을 가졌고, 필터 역시 세로•가로 뱡향의 차원을 갖는다.\n",
    "데이터와 필터의 형상을 (높이, 너비)로 표시하고, 입력은 (4, 4), 필터는 (3, ,3), 출력은 (2, 2)가 된다. 문헌에 따라 필터를 커널이라 칭하기도 한다.\n",
    "\n",
    "합성곱 연산은 필터의 윈도우를 일정 간격으로 이동해 가면서 입력데이터를 적용한다.\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_A253027AE53F-1.jpeg)\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_0B5440F6507D-1.jpeg)\n",
    "\n",
    "완전연결 신경망에서는 가중치 매개변수가 존재하는데, CNN에서는 필터의 매개변수가 그 동안의 가중치에 해당한다.\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_48310C0B89B8-1.jpeg)\n",
    "\n",
    "편향은 항상 (1 X 1)만 존재한다.\n",
    "\n",
    "### 패딩\n",
    "\n",
    "합성곱 연산을 수행하기전에 입력데이터 주변을 특정값으로 채우기도 한다. 이를 패딩이라고 부른다.\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_909BE542662C-1.jpeg)\n",
    "\n",
    "패딩은 주로 출력 크기를 조정할 목적으로 사용한다. 합성곱 연산을 거칠때마다. 크기가 작아지면서 어느 시점에는 출력의 크기가 1이 되어 버린다. 이러한 사태를 막기위해 패딩을 사용한다.\n",
    "\n",
    "\n",
    "### 스트라이드\n",
    "\n",
    "필터를 적용하는 위치 간격을 스트라이드라고 한다.\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_FEACB8608D3C-1.jpeg)\n",
    "\n",
    "\n",
    "\n",
    "입력 크기를 (H, W), 필터 크기를 (FH, FW), 출력 크기를 (OH, OW) 패딩을 P, 스트라이드를 S라 하면 출력 크기는 다음식으로 계산한다.\n",
    "\n",
    "$OH = \\frac{H+2P-FH}{S} + 1$\n",
    "\n",
    "$OW = \\frac{W+2P-FW}{S} + 1$\n",
    "\n",
    "\n",
    "### 3차원 데이터 합성곱 연산\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_CF9F402AD153-1.jpeg)\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_1CE60FEFACB1-1.jpeg)\n",
    "\n",
    "3차원의 합성곱 연산에서 주의할 점은 입력 데이터의 채널수와 필터의 채널 수가 같아야 한다는 것이다.\n",
    "\n",
    "#### 블록으로 생각하기\n",
    "\n",
    "3차원의 합성곱 연산은 데이터와 필터를 직육면체 블록이라고 생각하면 쉽다.\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_1617A6F5BEF7-1.jpeg)\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_99E3F20860B6-1.jpeg)\n",
    "\n",
    "필터를 FN개 적용하면 출력맵도 FN개가 생성된다.\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_98B1495566CB-1.jpeg)\n",
    "\n",
    "편향은 채널 하나에 값 하나씩으로 구성된다.\n",
    "\n",
    "### 배치처리\n",
    "\n",
    "신경망 처리에서는 입력데이터를 한 덩어리로 묶어 배치로 처리했다. 완전연결 신경망을 구현하면서는 이 방식을 지원하여 처리 효율을 높이고 미니배치 방식의 학습도 지원하도록 했다.\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_1879549FDD73-1.jpeg)\n",
    "\n",
    "신경망에 4차원 데이터가 하나 흐를때마다 데이터 N개에 대한 합성곱 연산이 이뤄진다는 것이다. 즉, N회분의 처리를 한번에 수행하는 것이다.\n",
    "\n",
    "### 풀링 계층\n",
    "\n",
    "풀링은 세로•가로 방향의 공간을 줄이는 연산이다.\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_6D50AC245FB7-1.jpeg)\n",
    "\n",
    "최대 풀링을 스트라이드 2로 처리하는 순서이다.\n",
    "풀링은 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정하는게 일반적이다.\n",
    "\n",
    "#### 플링 계층의 특징\n",
    "\n",
    "\n",
    "* 학습해야할 매개변수가 없다.\n",
    "    - 풀링 계층은 함성곱 계층과 달리 학습해야할 매개변수가 없다. 풀링은 대상 영역에서 최댓값이나 평균을 취하는 명환한 처리 이므로 특별히 학습할 것이 없다.\n",
    "* 채널수가 변하지 않는다.\n",
    "    - 풀링 연산을 입력데이터의 채널 수 그대로 출력 데이터로 내보낸다.\n",
    "* 입력의 변화에 영향을 적게 받는다.\n",
    "    - 입력데이터가 조금 변해도 풀링의 결과는 잘 변하지 않는다.\n",
    "\n",
    "\n",
    "### AlexNet\n",
    "\n",
    "AlexNet은 합성곱 계층과 풀링 계층을 거듭하며 마지막으로 완전 연결계층을 거쳐 결과를 출력한다.\n",
    "* 활성화 함수로 ReLU를 이용한다.\n",
    "* LRN이라는 국소적 정규화를 실시하는 계층을 이용한다.\n",
    "* 드롭아웃을 사용한다.\n",
    "\n",
    "#### 층을 깊게 하는 이유\n",
    "\n",
    "층을 깊게 할떄의 이점을 보면, 하나는 신경망의 매개변수 수가 줄어든다는 것이다. 층을 깊게한 신경망은 깊지 않은 경우보다 적은 매개변수로 같은(혹은 그 이상) 수준의 표현력을 달성할 수 있다.\n",
    "\n",
    "![](/Users/taewoong/Documents/NLP_1/img/IMG_E7D873293C8E-1.jpeg)\n",
    "\n",
    "\n",
    "$5 \\times 5$ 합성곱 연산은 1회는 $3 \\times 3$의 합성곱 연산을 2회 수행하여 대체 할 수가 있다. 게다가 전자의 경우 매개변수가 25(5x5)개인 반면, 후자는 총 18개(2X3X3)이며, 매개변수 수는 층을 반복할 수록 적어진다.\n",
    "\n",
    "작은 필터를 겹쳐 신경망을 깊게 할때의 장점은 매개변수를 줄여 넓은 수용영역을 소화할 수 있다는데 있다. 게다가 층을 거듭하면서 ReLU 등의 활성화 함수를 합성곱 계층\n",
    "사이에 끼움으로써 신경망의 표현력이 개선된다.\n",
    "이는 활성화 함수가 신경망에 '비선형'힘을 가하고 비선형 함수가 겹치면서 더 복잡한 것도 표현할 수 있게 되기 때문이다.\n",
    "\n",
    "층을 깊게 함으로써 학습데이터의 양을 줄여 학습을 고속으로 수행할 수 있다. 신경망을 깊게하면 학습해야할 문제를 계측적으로 분해할 수 있다. 각 층이 학습해야할\n",
    "문제르 더 단순한 문제로 대체할 수 있는 것이다.\n",
    "\n",
    "층을 깊게하면 정보를 계층적으로 전달할 수 있다. 즉, 층을 깊이 함으로써 각 층이 학습해야할 문제를 '풀기 쉬운 단순한 문제'로 분해할 수 있어 효율적이다.\n",
    "\n",
    "\n",
    "\n",
    "## CODE\n",
    "### 첫번째 표기 방법\n",
    "\n",
    "합성곱(nn.Cov2D) + 활성화 함수(nn.ReLU)를 하나의 합성곱 층으로 보고, 맥스풀링(nn.MaxPoold2d)은 풀링 층으로 별도로 명명한다.\n",
    "### 두번째 표기 방법\n",
    "합성곱(nn.Conv2d) + 활성화 함수(nn.ReLU) + 맥스풀링(nn.MaxPoold2d)을 하나의 합성곱 층으로 봅니다.\n",
    "\n",
    "다시 말해 풀링도 하나의 층으로 보느냐, 안 보느냐의 문제인데 누가 옳고 틀리냐의 문제는 아니므로, 이번 챕터에서는 편의를 위해 맥스풀링까지도 포함해서 하나의 합성곱 층으로 판단하고 정리해보겠습니다. 다시 말해 두번째 표기 방법을 택하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서의 크기 : torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 배치 크기 × 채널 × 높이(height) × 너비(widht)의 크기의 텐서를 선언\n",
    "inputs = torch.Tensor(1, 1, 28, 28)\n",
    "print('텐서의 크기 : {}'.format(inputs.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 합성곱층과 풀링 선언하기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "print(conv1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "print(conv2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "print(pool)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 구현체를 연결하여 모델 만들기\n",
    "지금까지는 선언만한 것이고 아직 이들을 연결시키지는 않았습니다. 이들을 연결시켜서 모델을 완성시켜보겠습니다. 우선 입력을 첫번째 합성곱층을 통과시키고 합성곱층을 통과시킨 후의 텐서의 크기를 보겠습니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 28, 28])\n",
      "torch.Size([1, 32, 14, 14])\n",
      "torch.Size([1, 64, 14, 14])\n",
      "torch.Size([1, 64, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "out = conv1(inputs)\n",
    "print(out.shape)\n",
    "out = pool(out)\n",
    "print(out.shape)\n",
    "out = conv2(out)\n",
    "print(out.shape)\n",
    "out = pool(out)\n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136])\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 차원인 배치 차원은 그대로 두고 나머지는 펼쳐라\n",
    "out = out.view(out.size(0), -1)\n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "배치 차원을 제외하고 모두 하나의 차원으로 통합된 것을 볼 수 있습니다. 이제 이에 대해서 전결합층(Fully-Connteced layer)를 통과시켜보겠습니다. 출력층으로 10개의 뉴런을 배치하여 10개 차원의 텐서로 변환합니다.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(3136, 10) # input_dim = 3,136, output_dim = 10\n",
    "out = fc(out)\n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CNN으로 MNIST 분류하기\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d883fa6457d49f5b94ed3b5e830490c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f1cbce3439e453e9b45e25c2a5fce73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd5bb035d405443cac82ecac4fd78866"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "935ce49b83d54ee18b608454d237be37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
    "                          transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n",
    "                         transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                         download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 첫번째층\n",
    "        # ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # 두번째층\n",
    "        # ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
    "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
    "\n",
    "        # 전결합층 한정으로 가중치 초기화\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = CNN()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 600\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.238453925\n",
      "[Epoch:    2] cost = 0.0623652861\n",
      "[Epoch:    3] cost = 0.0450601764\n",
      "[Epoch:    4] cost = 0.0369159319\n",
      "[Epoch:    5] cost = 0.0306813829\n",
      "[Epoch:    6] cost = 0.025768565\n",
      "[Epoch:    7] cost = 0.0210375804\n",
      "[Epoch:    8] cost = 0.0177947525\n",
      "[Epoch:    9] cost = 0.0152741205\n",
      "[Epoch:   10] cost = 0.0128973806\n",
      "[Epoch:   11] cost = 0.0116970744\n",
      "[Epoch:   12] cost = 0.00900935382\n",
      "[Epoch:   13] cost = 0.00903830398\n",
      "[Epoch:   14] cost = 0.00581437256\n",
      "[Epoch:   15] cost = 0.00809787307\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9825999736785889\n"
     ]
    }
   ],
   "source": [
    "# 학습을 진행하지 않을 것이므로 torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float()\n",
    "    Y_test = mnist_test.test_labels\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 깊은 CNN으로 MNIST 분류하기\n",
    "#### 1번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 1, out_channel = 32, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2))\n",
    "\n",
    "#### 2번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 32, out_channel = 64, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2))\n",
    "\n",
    "#### 3번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 64, out_channel = 128, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2, padding=1))\n",
    "\n",
    "#### 4번 레이어 : 전결합층(Fully-Connected layer)\n",
    "특성맵을 펼친다. # batch_size × 4 × 4 × 128 → batch_size × 2048\n",
    "전결합층(뉴런 625개) + 활성화 함수 ReLU\n",
    "\n",
    "#### 5번 레이어 : 전결합층(Fully-Connected layer)\n",
    "전결합층(뉴런 10개) + 활성화 함수 Softmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 5\n",
    "batch_size = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*128, 625, bias=True)\n",
    "        nn.init.xavier_uniform(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - self.keep_prob))\n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.layer4(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2048, out_features=625, bias=True)\n",
      "  (layer4): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=625, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc2): Linear(in_features=625, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 600\n",
      "[Epoch:    1] cost = 0.186970517\n",
      "[Epoch:    2] cost = 0.0512601361\n",
      "[Epoch:    3] cost = 0.0363969505\n",
      "[Epoch:    4] cost = 0.026845675\n",
      "[Epoch:    5] cost = 0.0234171487\n",
      "[Epoch:    6] cost = 0.0194083806\n",
      "[Epoch:    7] cost = 0.0164346397\n",
      "[Epoch:    8] cost = 0.013707974\n",
      "[Epoch:    9] cost = 0.0127727576\n",
      "[Epoch:   10] cost = 0.0115109021\n",
      "[Epoch:   11] cost = 0.00960298255\n",
      "[Epoch:   12] cost = 0.00824443344\n",
      "[Epoch:   13] cost = 0.00857233535\n",
      "[Epoch:   14] cost = 0.00876263995\n",
      "[Epoch:   15] cost = 0.00630045636\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9865999817848206\n"
     ]
    }
   ],
   "source": [
    "# 학습을 진행하지 않을 것이므로 torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float()\n",
    "    Y_test = mnist_test.test_labels\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}